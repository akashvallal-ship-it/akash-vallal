{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c7e23b1-aa73-45c8-afd2-0f324a8251b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "from typing import List, Tuple\n",
    "\n",
    "from autogen_core import (\n",
    "    FunctionCall,\n",
    "    MessageContext,\n",
    "    RoutedAgent,\n",
    "    SingleThreadedAgentRuntime,\n",
    "    TopicId,\n",
    "    TypeSubscription,\n",
    "    message_handler,\n",
    ")\n",
    "from autogen_core.models import (\n",
    "    AssistantMessage,\n",
    "    ChatCompletionClient,\n",
    "    FunctionExecutionResult,\n",
    "    FunctionExecutionResultMessage,\n",
    "    LLMMessage,\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    ")\n",
    "from autogen_core.tools import FunctionTool, Tool\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d350b65-f80b-43c5-ac3a-f8946d483db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserLogin(BaseModel):\n",
    "    pass\n",
    "\n",
    "\n",
    "class UserTask(BaseModel):\n",
    "    context: List[LLMMessage]\n",
    "\n",
    "\n",
    "class AgentResponse(BaseModel):\n",
    "    reply_to_topic_type: str\n",
    "    context: List[LLMMessage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "167aceb1-a0ea-4f9b-9626-fb71e700f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIAgent(RoutedAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        description: str,\n",
    "        system_message: SystemMessage,\n",
    "        model_client: ChatCompletionClient,\n",
    "        tools: List[Tool],\n",
    "        delegate_tools: List[Tool],\n",
    "        agent_topic_type: str,\n",
    "        user_topic_type: str,\n",
    "    ) -> None:\n",
    "        super().__init__(description)\n",
    "        self._system_message = system_message\n",
    "        self._model_client = model_client\n",
    "        self._tools = dict([(tool.name, tool) for tool in tools])\n",
    "        self._tool_schema = [tool.schema for tool in tools]\n",
    "        self._delegate_tools = dict([(tool.name, tool) for tool in delegate_tools])\n",
    "        self._delegate_tool_schema = [tool.schema for tool in delegate_tools]\n",
    "        self._agent_topic_type = agent_topic_type\n",
    "        self._user_topic_type = user_topic_type\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_task(self, message: UserTask, ctx: MessageContext) -> None:\n",
    "        # Send the task to the LLM.\n",
    "        llm_result = await self._model_client.create(\n",
    "            messages=[self._system_message] + message.context,\n",
    "            tools=self._tool_schema + self._delegate_tool_schema,\n",
    "            cancellation_token=ctx.cancellation_token,\n",
    "        )\n",
    "        print(f\"{'-'*80}\\n{self.id.type}:\\n{llm_result.content}\", flush=True)\n",
    "        # Process the LLM result.\n",
    "        while isinstance(llm_result.content, list) and all(isinstance(m, FunctionCall) for m in llm_result.content):\n",
    "            tool_call_results: List[FunctionExecutionResult] = []\n",
    "            delegate_targets: List[Tuple[str, UserTask]] = []\n",
    "            # Process each function call.\n",
    "            for call in llm_result.content:\n",
    "                arguments = json.loads(call.arguments)\n",
    "                if call.name in self._tools:\n",
    "                    # Execute the tool directly.\n",
    "                    result = await self._tools[call.name].run_json(arguments, ctx.cancellation_token)\n",
    "                    result_as_str = self._tools[call.name].return_value_as_string(result)\n",
    "                    tool_call_results.append(\n",
    "                        FunctionExecutionResult(call_id=call.id, content=result_as_str, is_error=False, name=call.name)\n",
    "                    )\n",
    "                elif call.name in self._delegate_tools:\n",
    "                    # Execute the tool to get the delegate agent's topic type.\n",
    "                    result = await self._delegate_tools[call.name].run_json(arguments, ctx.cancellation_token)\n",
    "                    topic_type = self._delegate_tools[call.name].return_value_as_string(result)\n",
    "                    # Create the context for the delegate agent, including the function call and the result.\n",
    "                    delegate_messages = list(message.context) + [\n",
    "                        AssistantMessage(content=[call], source=self.id.type),\n",
    "                        FunctionExecutionResultMessage(\n",
    "                            content=[\n",
    "                                FunctionExecutionResult(\n",
    "                                    call_id=call.id,\n",
    "                                    content=f\"Transferred to {topic_type}. Adopt persona immediately.\",\n",
    "                                    is_error=False,\n",
    "                                    name=call.name,\n",
    "                                )\n",
    "                            ]\n",
    "                        ),\n",
    "                    ]\n",
    "                    delegate_targets.append((topic_type, UserTask(context=delegate_messages)))\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown tool: {call.name}\")\n",
    "            if len(delegate_targets) > 0:\n",
    "                # Delegate the task to other agents by publishing messages to the corresponding topics.\n",
    "                for topic_type, task in delegate_targets:\n",
    "                    print(f\"{'-'*80}\\n{self.id.type}:\\nDelegating to {topic_type}\", flush=True)\n",
    "                    await self.publish_message(task, topic_id=TopicId(topic_type, source=self.id.key))\n",
    "            if len(tool_call_results) > 0:\n",
    "                print(f\"{'-'*80}\\n{self.id.type}:\\n{tool_call_results}\", flush=True)\n",
    "                # Make another LLM call with the results.\n",
    "                message.context.extend(\n",
    "                    [\n",
    "                        AssistantMessage(content=llm_result.content, source=self.id.type),\n",
    "                        FunctionExecutionResultMessage(content=tool_call_results),\n",
    "                    ]\n",
    "                )\n",
    "                llm_result = await self._model_client.create(\n",
    "                    messages=[self._system_message] + message.context,\n",
    "                    tools=self._tool_schema + self._delegate_tool_schema,\n",
    "                    cancellation_token=ctx.cancellation_token,\n",
    "                )\n",
    "                print(f\"{'-'*80}\\n{self.id.type}:\\n{llm_result.content}\", flush=True)\n",
    "            else:\n",
    "                # The task has been delegated, so we are done.\n",
    "                return\n",
    "        # The task has been completed, publish the final result.\n",
    "        assert isinstance(llm_result.content, str)\n",
    "        message.context.append(AssistantMessage(content=llm_result.content, source=self.id.type))\n",
    "        await self.publish_message(\n",
    "            AgentResponse(context=message.context, reply_to_topic_type=self._agent_topic_type),\n",
    "            topic_id=TopicId(self._user_topic_type, source=self.id.key),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fede6cb-4f5e-45de-a8f1-3124c228e84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanAgent(RoutedAgent):\n",
    "    def __init__(self, description: str, agent_topic_type: str, user_topic_type: str) -> None:\n",
    "        super().__init__(description)\n",
    "        self._agent_topic_type = agent_topic_type\n",
    "        self._user_topic_type = user_topic_type\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_user_task(self, message: UserTask, ctx: MessageContext) -> None:\n",
    "        human_input = input(\"Human agent input: \")\n",
    "        print(f\"{'-'*80}\\n{self.id.type}:\\n{human_input}\", flush=True)\n",
    "        message.context.append(AssistantMessage(content=human_input, source=self.id.type))\n",
    "        await self.publish_message(\n",
    "            AgentResponse(context=message.context, reply_to_topic_type=self._agent_topic_type),\n",
    "            topic_id=TopicId(self._user_topic_type, source=self.id.key),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4ccc5d3-a171-4bfe-bfa2-270c95873751",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserAgent(RoutedAgent):\n",
    "    def __init__(self, description: str, user_topic_type: str, agent_topic_type: str) -> None:\n",
    "        super().__init__(description)\n",
    "        self._user_topic_type = user_topic_type\n",
    "        self._agent_topic_type = agent_topic_type\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_user_login(self, message: UserLogin, ctx: MessageContext) -> None:\n",
    "        print(f\"{'-'*80}\\nUser login, session ID: {self.id.key}.\", flush=True)\n",
    "        # Get the user's initial input after login.\n",
    "        user_input = input(\"User: \")\n",
    "        print(f\"{'-'*80}\\n{self.id.type}:\\n{user_input}\")\n",
    "        await self.publish_message(\n",
    "            UserTask(context=[UserMessage(content=user_input, source=\"User\")]),\n",
    "            topic_id=TopicId(self._agent_topic_type, source=self.id.key),\n",
    "        )\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_task_result(self, message: AgentResponse, ctx: MessageContext) -> None:\n",
    "        # Get the user's input after receiving a response from an agent.\n",
    "        user_input = input(\"User (type 'exit' to close the session): \")\n",
    "        print(f\"{'-'*80}\\n{self.id.type}:\\n{user_input}\", flush=True)\n",
    "        if user_input.strip().lower() == \"exit\":\n",
    "            print(f\"{'-'*80}\\nUser session ended, session ID: {self.id.key}.\")\n",
    "            return\n",
    "        message.context.append(UserMessage(content=user_input, source=\"User\"))\n",
    "        await self.publish_message(\n",
    "            UserTask(context=message.context), topic_id=TopicId(message.reply_to_topic_type, source=self.id.key)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "896f1d5a-e826-4a71-8b27-b73d99182b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_order(product: str, price: int) -> str:\n",
    "    print(\"\\n\\n=== Order Summary ===\")\n",
    "    print(f\"Product: {product}\")\n",
    "    print(f\"Price: ${price}\")\n",
    "    print(\"=================\\n\")\n",
    "    confirm = input(\"Confirm order? y/n: \").strip().lower()\n",
    "    if confirm == \"y\":\n",
    "        print(\"Order execution successful!\")\n",
    "        return \"Success\"\n",
    "    else:\n",
    "        print(\"Order cancelled!\")\n",
    "        return \"User cancelled order.\"\n",
    "\n",
    "\n",
    "def look_up_item(search_query: str) -> str:\n",
    "    item_id = \"item_132612938\"\n",
    "    print(\"Found item:\", item_id)\n",
    "    return item_id\n",
    "\n",
    "\n",
    "def execute_refund(item_id: str, reason: str = \"not provided\") -> str:\n",
    "    print(\"\\n\\n=== Refund Summary ===\")\n",
    "    print(f\"Item ID: {item_id}\")\n",
    "    print(f\"Reason: {reason}\")\n",
    "    print(\"=================\\n\")\n",
    "    print(\"Refund execution successful!\")\n",
    "    return \"success\"\n",
    "\n",
    "\n",
    "execute_order_tool = FunctionTool(execute_order, description=\"Price should be in USD.\")\n",
    "look_up_item_tool = FunctionTool(\n",
    "    look_up_item, description=\"Use to find item ID.\\nSearch query can be a description or keywords.\"\n",
    ")\n",
    "execute_refund_tool = FunctionTool(execute_refund, description=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8404006-8ee4-4cbb-bc2d-fa01ab0295ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_agent_topic_type = \"SalesAgent\"\n",
    "issues_and_repairs_agent_topic_type = \"IssuesAndRepairsAgent\"\n",
    "triage_agent_topic_type = \"TriageAgent\"\n",
    "human_agent_topic_type = \"HumanAgent\"\n",
    "user_topic_type = \"User\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9d1ee43-6a1f-4417-81e3-65c7b75753ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_to_sales_agent() -> str:\n",
    "    return sales_agent_topic_type\n",
    "\n",
    "\n",
    "def transfer_to_issues_and_repairs() -> str:\n",
    "    return issues_and_repairs_agent_topic_type\n",
    "\n",
    "\n",
    "def transfer_back_to_triage() -> str:\n",
    "    return triage_agent_topic_type\n",
    "\n",
    "\n",
    "def escalate_to_human() -> str:\n",
    "    return human_agent_topic_type\n",
    "\n",
    "\n",
    "transfer_to_sales_agent_tool = FunctionTool(\n",
    "    transfer_to_sales_agent, description=\"Use for anything sales or buying related.\"\n",
    ")\n",
    "transfer_to_issues_and_repairs_tool = FunctionTool(\n",
    "    transfer_to_issues_and_repairs, description=\"Use for issues, repairs, or refunds.\"\n",
    ")\n",
    "transfer_back_to_triage_tool = FunctionTool(\n",
    "    transfer_back_to_triage,\n",
    "    description=\"Call this if the user brings up a topic outside of your purview,\\nincluding escalating to human.\",\n",
    ")\n",
    "escalate_to_human_tool = FunctionTool(escalate_to_human, description=\"Only call this if explicitly asked to.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64e317dd-bab9-4e93-98ea-7b8c247fe0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = SingleThreadedAgentRuntime()\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    # api_key=\"YOUR_API_KEY\",\n",
    ")\n",
    "\n",
    "# Register the triage agent.\n",
    "triage_agent_type = await AIAgent.register(\n",
    "    runtime,\n",
    "    type=triage_agent_topic_type,  # Using the topic type as the agent type.\n",
    "    factory=lambda: AIAgent(\n",
    "        description=\"A triage agent.\",\n",
    "        system_message=SystemMessage(\n",
    "            content=\"You are a customer service bot for ACME Inc. \"\n",
    "            \"Introduce yourself. Always be very brief. \"\n",
    "            \"Gather information to direct the customer to the right department. \"\n",
    "            \"But make your questions subtle and natural.\"\n",
    "        ),\n",
    "        model_client=model_client,\n",
    "        tools=[],\n",
    "        delegate_tools=[\n",
    "            transfer_to_issues_and_repairs_tool,\n",
    "            transfer_to_sales_agent_tool,\n",
    "            escalate_to_human_tool,\n",
    "        ],\n",
    "        agent_topic_type=triage_agent_topic_type,\n",
    "        user_topic_type=user_topic_type,\n",
    "    ),\n",
    ")\n",
    "# Add subscriptions for the triage agent: it will receive messages published to its own topic only.\n",
    "await runtime.add_subscription(TypeSubscription(topic_type=triage_agent_topic_type, agent_type=triage_agent_type.type))\n",
    "\n",
    "# Register the sales agent.\n",
    "sales_agent_type = await AIAgent.register(\n",
    "    runtime,\n",
    "    type=sales_agent_topic_type,  # Using the topic type as the agent type.\n",
    "    factory=lambda: AIAgent(\n",
    "        description=\"A sales agent.\",\n",
    "        system_message=SystemMessage(\n",
    "            content=\"You are a sales agent for ACME Inc.\"\n",
    "            \"Always answer in a sentence or less.\"\n",
    "            \"Follow the following routine with the user:\"\n",
    "            \"1. Ask them about any problems in their life related to catching roadrunners.\\n\"\n",
    "            \"2. Casually mention one of ACME's crazy made-up products can help.\\n\"\n",
    "            \" - Don't mention price.\\n\"\n",
    "            \"3. Once the user is bought in, drop a ridiculous price.\\n\"\n",
    "            \"4. Only after everything, and if the user says yes, \"\n",
    "            \"tell them a crazy caveat and execute their order.\\n\"\n",
    "            \"\"\n",
    "        ),\n",
    "        model_client=model_client,\n",
    "        tools=[execute_order_tool],\n",
    "        delegate_tools=[transfer_back_to_triage_tool],\n",
    "        agent_topic_type=sales_agent_topic_type,\n",
    "        user_topic_type=user_topic_type,\n",
    "    ),\n",
    ")\n",
    "# Add subscriptions for the sales agent: it will receive messages published to its own topic only.\n",
    "await runtime.add_subscription(TypeSubscription(topic_type=sales_agent_topic_type, agent_type=sales_agent_type.type))\n",
    "\n",
    "# Register the issues and repairs agent.\n",
    "issues_and_repairs_agent_type = await AIAgent.register(\n",
    "    runtime,\n",
    "    type=issues_and_repairs_agent_topic_type,  # Using the topic type as the agent type.\n",
    "    factory=lambda: AIAgent(\n",
    "        description=\"An issues and repairs agent.\",\n",
    "        system_message=SystemMessage(\n",
    "            content=\"You are a customer support agent for ACME Inc.\"\n",
    "            \"Always answer in a sentence or less.\"\n",
    "            \"Follow the following routine with the user:\"\n",
    "            \"1. First, ask probing questions and understand the user's problem deeper.\\n\"\n",
    "            \" - unless the user has already provided a reason.\\n\"\n",
    "            \"2. Propose a fix (make one up).\\n\"\n",
    "            \"3. ONLY if not satisfied, offer a refund.\\n\"\n",
    "            \"4. If accepted, search for the ID and then execute refund.\"\n",
    "        ),\n",
    "        model_client=model_client,\n",
    "        tools=[\n",
    "            execute_refund_tool,\n",
    "            look_up_item_tool,\n",
    "        ],\n",
    "        delegate_tools=[transfer_back_to_triage_tool],\n",
    "        agent_topic_type=issues_and_repairs_agent_topic_type,\n",
    "        user_topic_type=user_topic_type,\n",
    "    ),\n",
    ")\n",
    "# Add subscriptions for the issues and repairs agent: it will receive messages published to its own topic only.\n",
    "await runtime.add_subscription(\n",
    "    TypeSubscription(topic_type=issues_and_repairs_agent_topic_type, agent_type=issues_and_repairs_agent_type.type)\n",
    ")\n",
    "\n",
    "# Register the human agent.\n",
    "human_agent_type = await HumanAgent.register(\n",
    "    runtime,\n",
    "    type=human_agent_topic_type,  # Using the topic type as the agent type.\n",
    "    factory=lambda: HumanAgent(\n",
    "        description=\"A human agent.\",\n",
    "        agent_topic_type=human_agent_topic_type,\n",
    "        user_topic_type=user_topic_type,\n",
    "    ),\n",
    ")\n",
    "# Add subscriptions for the human agent: it will receive messages published to its own topic only.\n",
    "await runtime.add_subscription(TypeSubscription(topic_type=human_agent_topic_type, agent_type=human_agent_type.type))\n",
    "\n",
    "# Register the user agent.\n",
    "user_agent_type = await UserAgent.register(\n",
    "    runtime,\n",
    "    type=user_topic_type,\n",
    "    factory=lambda: UserAgent(\n",
    "        description=\"A user agent.\",\n",
    "        user_topic_type=user_topic_type,\n",
    "        agent_topic_type=triage_agent_topic_type,  # Start with the triage agent.\n",
    "    ),\n",
    ")\n",
    "# Add subscriptions for the user agent: it will receive messages published to its own topic only.\n",
    "await runtime.add_subscription(TypeSubscription(topic_type=user_topic_type, agent_type=user_agent_type.type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b352b5f-f723-43b7-8ae9-4fea50d6c196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "User login, session ID: 27ed6e37-1a19-4919-a94f-c3964848840c.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  i want a refund\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "User:\n",
      "i want a refund\n",
      "--------------------------------------------------------------------------------\n",
      "TriageAgent:\n",
      "I can help with that! Can you share what item you need a refund for or if there are any specific issues you're experiencing?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User (type 'exit' to close the session):  I bought a pair of shoes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "User:\n",
      "I bought a pair of shoes\n",
      "--------------------------------------------------------------------------------\n",
      "TriageAgent:\n",
      "[FunctionCall(id='call_VHPopXDGroHmT8zQEX04D4cj', arguments='{}', name='transfer_to_issues_and_repairs')]\n",
      "--------------------------------------------------------------------------------\n",
      "TriageAgent:\n",
      "Delegating to IssuesAndRepairsAgent\n",
      "--------------------------------------------------------------------------------\n",
      "IssuesAndRepairsAgent:\n",
      "I'm unable to assist with that directly, but a representative will be with you shortly to help. Thank you for your patience!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User (type 'exit' to close the session):  i want refund for pair of shoes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "User:\n",
      "i want refund for pair of shoes\n",
      "--------------------------------------------------------------------------------\n",
      "IssuesAndRepairsAgent:\n",
      "Could you please provide a reason for the refund request, or any issues you faced with the shoes?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User (type 'exit' to close the session):  small size of shoes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "User:\n",
      "small size of shoes\n",
      "--------------------------------------------------------------------------------\n",
      "IssuesAndRepairsAgent:\n",
      "[FunctionCall(id='call_DOnyJsnaqZKfr4gwQvn723f5', arguments='{\"search_query\":\"pair of shoes\"}', name='look_up_item')]\n",
      "Found item: item_132612938\n",
      "--------------------------------------------------------------------------------\n",
      "IssuesAndRepairsAgent:\n",
      "[FunctionExecutionResult(content='item_132612938', name='look_up_item', call_id='call_DOnyJsnaqZKfr4gwQvn723f5', is_error=False)]\n",
      "--------------------------------------------------------------------------------\n",
      "IssuesAndRepairsAgent:\n",
      "[FunctionCall(id='call_JpijpsqDS9m6KBeOzUFgsjX4', arguments='{\"item_id\":\"item_132612938\",\"reason\":\"small size of shoes\"}', name='execute_refund')]\n",
      "\n",
      "\n",
      "=== Refund Summary ===\n",
      "Item ID: item_132612938\n",
      "Reason: small size of shoes\n",
      "=================\n",
      "\n",
      "Refund execution successful!\n",
      "--------------------------------------------------------------------------------\n",
      "IssuesAndRepairsAgent:\n",
      "[FunctionExecutionResult(content='success', name='execute_refund', call_id='call_JpijpsqDS9m6KBeOzUFgsjX4', is_error=False)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error processing publish message for IssuesAndRepairsAgent/27ed6e37-1a19-4919-a94f-c3964848840c\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\akash.vallal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py\", line 606, in _on_message\n",
      "    return await agent.on_message(\n",
      "  File \"C:\\Users\\akash.vallal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\autogen_core\\_base_agent.py\", line 119, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "  File \"C:\\Users\\akash.vallal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\autogen_core\\_routed_agent.py\", line 485, in on_message_impl\n",
      "    return await h(self, message, ctx)\n",
      "  File \"C:\\Users\\akash.vallal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\autogen_core\\_routed_agent.py\", line 149, in wrapper\n",
      "    return_value = await func(self, message, ctx)\n",
      "  File \"C:\\Users\\akash.vallal\\AppData\\Local\\Temp\\ipykernel_11260\\2814613610.py\", line 80, in handle_task\n",
      "    llm_result = await self._model_client.create(\n",
      "  File \"C:\\Users\\akash.vallal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py\", line 704, in create\n",
      "    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n",
      "  File \"C:\\Users\\akash.vallal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2585, in create\n",
      "    return await self._post(\n",
      "  File \"C:\\Users\\akash.vallal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"C:\\Users\\akash.vallal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-sG8oFB3lS9nXEaJz2OlAFEw5 on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "# Start the runtime.\n",
    "runtime.start()\n",
    "\n",
    "# Create a new session for the user.\n",
    "session_id = str(uuid.uuid4())\n",
    "await runtime.publish_message(UserLogin(), topic_id=TopicId(user_topic_type, source=session_id))\n",
    "\n",
    "# Run until completion.\n",
    "await runtime.stop_when_idle()\n",
    "await model_client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
